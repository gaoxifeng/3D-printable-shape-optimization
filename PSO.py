from TopologyOp import TopoOpt
from Render_Fields_modified import Render_Fields
import torch
import numpy as np
import mcubes
import argparse
import os
import logging
import tqdm
def extract_fields(bound_min, bound_max, resolution, query_func):
    N = 64
    X = torch.linspace(bound_min[0], bound_max[0], resolution).split(N)
    Y = torch.linspace(bound_min[1], bound_max[1], resolution).split(N)
    Z = torch.linspace(bound_min[2], bound_max[2], resolution).split(N)

    u = np.zeros([resolution, resolution, resolution], dtype=np.float32)
    with torch.no_grad():
        for xi, xs in enumerate(X):
            for yi, ys in enumerate(Y):
                for zi, zs in enumerate(Z):
                    xx, yy, zz = torch.meshgrid(xs, ys, zs)
                    pts = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1)
                    val = query_func(pts).reshape(len(xs), len(ys), len(zs)).detach().cpu().numpy()
                    u[xi * N: xi * N + len(xs), yi * N: yi * N + len(ys), zi * N: zi * N + len(zs)] = val
    return u


def extract_geometry(bound_min, bound_max, resolution, threshold, query_func):
    print('threshold: {}'.format(threshold))
    u = extract_fields(bound_min, bound_max, resolution, query_func)
    vertices, triangles = mcubes.marching_cubes(u, threshold)
    b_max_np = bound_max.detach().cpu().numpy()
    b_min_np = bound_min.detach().cpu().numpy()

    vertices = vertices / (resolution - 1.0) * (b_max_np - b_min_np)[None, :] + b_min_np[None, :]
    return vertices, triangles
"""
Step 1: Given any input mesh file obj, use NVidiff to prepare its masked rendering images

Step 2: Use the images to train NeuS network, and take another predefined Grid to optimize the shape

Step 3: Use the alternating way to train the NeuS network and do the TO alternatively.

Step 4: Optimize the final Mesh with some Regularization tools or methods for smooth surface reconstruction.
"""



class ADMM_3DPSO(torch.nn.Module):
    def __init__(self, MeshRender, FieldRender, TOptimizer):
        super().__init__()
        self.Mesh_R = MeshRender
        self.Field_R = FieldRender
        self.TOpt = TOptimizer

        #Is there anything else should I prepare for the Final Optimization precess?
        """
        Prepare two different sets of data:
        The first one is generated by the MeshRender and is used for our FieldRender
        The second one is generated by authors and is used for TOptimizer to optimize the shape or infill rate directly
        Combine these two parts then we could formulate our final loss functions and use a joint way to optimize by ADAM.
        """
        params_to_train = []
        params_to_train += list(self.Field_R.nerf_outside.parameters())
        params_to_train += list(self.Field_R.sdf_network.parameters())
        params_to_train += list(self.Field_R.deviation_network.parameters())
        self.optimizer = torch.optim.Adam(params_to_train, lr=self.learning_rate)


        # Prepare a initial data for the training process of TO
        # and then feed it into the TOpt
        #
        Pre_Grid = self.Field_R.generate_grid(shape=[x,y,z])





    def Alterating_train(self, steps, swap_steps, to_steps):
        #Prepare the Field Rendering Training process
        #Prepare the input data?
        #Train the Field Rendering Part
        #Train the TO part
        #Finalize the Final Output and make it smooth for visualization

        for iter_i in tqdm(range(steps)):
            if (iter_i+1) % swap_steps == 0:
                #We update the TO here

                Updated_Grid = self.TOpt.Opt3D_Grid(Pre_Grid, self.volfrac, p=3, rmin=1.5, maxloop=to_steps) #(dc,dv)
                #Here x should come from the NeuS model(which is the grid sample or infill sample to be updated)
                #Write a new function in TopologyOp to take x as input and return updated x after some steps

                update x for TOpt
                loss = TOpt_Loss
            else:
                #We update the Field here
                ###Or we just keep the training process inside the NeuS Field Rendering?
                ##But in this way we cannot connect with the gradient info from TO part
                Field_Loss = self.Field_R.train_ADMM(4, 512)
                loss = Field_Loss

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()






        # self.optimizer.zero_grad()
        # loss.backward()
        # self.optimizer.step()
        self.Field_R.validate_mesh(world_space=False, resolution=512, threshold=args.mcube_threshold)



        return None


    def Generate_mesh(self, SDF):
        #Return a mesh generated from the NeuS SDF
        return None

    def Visualization(self, original_mesh, generated_mesh):
        #Render two meshes together to compare the results of our TO
        #And the ideal case should be that the output of our method could outperform the original mesh in rendering image
        return None



if __name__ == "__main__":
    torch.set_default_tensor_type('torch.cuda.FloatTensor')

    FORMAT = "[%(filename)s:%(lineno)s - %(funcName)20s() ] %(message)s"
    logging.basicConfig(level=logging.DEBUG, format=FORMAT)

    parser = argparse.ArgumentParser()
    parser.add_argument('--conf', type=str, default='./confs/thin_structure.conf')
    parser.add_argument('--mode', type=str, default='train')
    parser.add_argument('--mcube_threshold', type=float, default=0.0)
    parser.add_argument('--is_continue', default=False, action="store_true")
    parser.add_argument('--gpu', type=int, default=0)
    parser.add_argument('--case', type=str, default='bmvs_bear')

    args = parser.parse_args()

    torch.cuda.set_device(args.gpu)
    args.conf = './confs/wmask_f16_modified.conf'
    args.field_shape = [64, 64, 64]
    args.method = 'Network'
    args.mode = 'train'
    args.case = 'cow'
    args.mesh_dir = 'data/cow2/cow.obj'
    args.out_dir = 'cow_modified'
    # args.MTL = './data/bunny/dancer_diffuse.mtl'
    args.MTL = None
    Field_runner = Render_Fields(args.mesh_dir, args.out_dir, args.conf, args.field_shape, args.MTL, args.method, args.mode, args.case)







    """
    Define the three runners first and then feed them into the ADMM_3DPSO runner for ADMM training
    Or, if we have already defined the Field_runner then we should ignore the Mesh_runner?
    
    """







    runner_ADMM = ADMM_3DPSO(Mesh_runner, Field_runner, TO_runner)